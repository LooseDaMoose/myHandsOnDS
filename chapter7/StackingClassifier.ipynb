{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "Run the individual classifiers from the previous exercise to make predictions on\n",
    "the validation set, and create a new training set with the resulting predictions:\n",
    "each training instance is a vector containing the set of predictions from all your\n",
    "classifiers for an image, and the target is the image’s class. Train a classifier on\n",
    "this new training set. Congratulations, you have just trained a blender, and\n",
    "together with the classifiers they form a stacking ensemble! Now let’s evaluate the\n",
    "ensemble on the test set. For each image in the test set, make predictions with all\n",
    "your classifiers, then feed the predictions to the blender to get the ensemble’s predictions.\n",
    "How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "#winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\", version = 1) # load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, vl, ts = 50000, 60000, 70000\n",
    "train, val, test = [x for x in range(tr)], [x for x in range(tr, vl)], [x for x in range(vl, ts)]\n",
    "X_train, X_val, X_test = mnist[\"data\"][train], mnist[\"data\"][val], mnist[\"data\"][test]\n",
    "y_train, y_val, y_test = mnist[\"target\"][train], mnist[\"target\"][val], mnist[\"target\"][test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "from sklearn.externals import joblib\n",
    "logreg_clf = joblib.load(\"logregMNIST.pkl\")\n",
    "rf_clf = joblib.load(\"rfMNIST.pkl\")\n",
    "xgb_clf = joblib.load(\"xgbMNIST.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run models on validation set and store the predictions. They will be the new features for our blender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred time: 0.5414106845855713\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "X_lr = logreg_clf.predict(X_val)\n",
    "X_rf = rf_clf.predict(X_val)\n",
    "X_xgb = xgb_clf.predict(X_val)\n",
    "time1 = time.time()\n",
    "winsound.Beep(freq, duration)\n",
    "print(\"Pred time: {}\".format(time1 - time0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stack = np.c_[X_lr, X_rf, X_xgb]\n",
    "# let's use a random forest as a blender\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "blender = RandomForestClassifier()\n",
    "blender.fit(X_stack, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingClassifier():\n",
    "    \"\"\"\n",
    "    class for stacking classifier:\n",
    "    arguments: list of classifiers (already fitted scikit-learn models), blender (sklearn model)\n",
    "    methods: fit, predict\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, blender):\n",
    "        self.clf = classifiers\n",
    "        self.bl = blender\n",
    "    def process(self, X):\n",
    "        \"\"\"\n",
    "        This method processes X features in X_stack predictions from the stacked classifiers\n",
    "        \"\"\"\n",
    "        # gather predictions from stacked models\n",
    "        X_stack = []\n",
    "        for clf in self.clf:\n",
    "            X_stack.append(clf.predict(X))\n",
    "        X_stack = np.c_[X_stack].transpose()\n",
    "        return(X_stack)        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        trains the blender model\n",
    "        \"\"\"\n",
    "        # gather predictions from stacked models\n",
    "        X_stack = self.process(X)\n",
    "        # train the blender\n",
    "        self.bl.fit(X_stack, y)        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        returns prediction from the blender model\n",
    "        \"\"\"\n",
    "        # process new features X into predictions of the stacked models\n",
    "        X_stack = self.process(X)\n",
    "        return(self.bl.predict(X_stack))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_clf = StackingClassifier([logreg_clf, rf_clf, xgb_clf], RandomForestClassifier())\n",
    "stack_clf.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = stack_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking accuracy: 0.9288\n",
      "Log Reg accuracy: 0.9122\n",
      "RF accuracy: 0.8703\n",
      "xgboost accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print(\"Stacking accuracy: {}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"Log Reg accuracy: {}\".format(accuracy_score(y_test, logreg_clf.predict(X_test))))\n",
    "print(\"RF accuracy: {}\".format(accuracy_score(y_test, rf_clf.predict(X_test))))\n",
    "print(\"xgboost accuracy: {}\".format(accuracy_score(y_test, xgb_clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost still king"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
