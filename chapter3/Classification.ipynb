{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## MNIST\n",
    "\n",
    "In this chapter we will be using the MNIST dataset, a set of 70k small images of digits handwritten by HS students and US employees. Each image is labeled with the digit it represents.\n",
    "This dataset is considered the \"Hello world\" of Machine Learning.\n",
    "\n",
    "Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them.\n",
    "The following code fetches the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\", version = 1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn generally have a similar dictionary structure including:\n",
    "\n",
    "- A DESCR key describing the dataset\n",
    "- A data key  containing an array with one row per instance and one column per feature\n",
    "- A target key containing an array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# let's look at these arrays:\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70k images, and each image has 784 features. This is because each image is 28x28 pixels, and each feature simply represents one pixel's intensity, from 0 (white) to 255 (black). Let's take a peek at one digit from the dataset. All you need to do is to grab an instance's feature vector, reshape it to a 28x28 array, and display it using Matplotlib's imshow() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a 5 and indeed that's what the label tells us\n",
    "Note that the label is a string. We prefer numbers, so let's cast y to ingegers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(y[0])\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! You should always create a ttest set and set it aside before inspecting the data closely. The MNIST dataset is actually already split into training set (the first 60k images) and a test set (the last 10k images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is already shuffled for us, which is good as this guarantees that all cross-validation folds will be similar (you don't want one fold to be missing some digits). Moreover, some learning algos are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row. Shuffling the dataset ensures that this won't happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "\n",
    "Let's simplify the problem for now and only try to identify one digit -- for example, the number 5. This \"5-detector\" will be an example of a *binary classifier* capable of distinguishing between two classes, 5 and NOT 5. Let's create the target vectors for this classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)  #Boolean vector, True for 5s, False for all other digits\n",
    "y_test = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's pick a classifier and train it, A good place to start is with a *Stochastic Gradient Descent* (SGD) classifier, using Scikit-Learn's SGDClassifier class.\n",
    "\n",
    "This classifier has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training istances independently, one at a time (which also makes SGD well suited for *online learning*), as we will see later. \n",
    "\n",
    "Let's create an SGDClassifier and train it on the whole training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\"\"\"\n",
    "The SGDClassifier relies on randomness during training (hence the name stochastic). \n",
    "If you want reproducible results, you should set the random_state parameter\n",
    "\"\"\"\n",
    "# Now you can use it to detect images of the number 5:\n",
    "print(sgd_clf.predict([some_digit]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will spend a large part of this chapter on this topic. There are many peformance measures available.\n",
    "\n",
    "### Measuring Accuracy Using Cross-Validation\n",
    "A good way to evaluate a model is to use cross-validation.\n",
    "\n",
    "#### Implementing Cross-Validation\n",
    "Occasionally you will need more control over the cross-validation process than what Scikit-Learn provides off-the-shelf. In these cases, you can implement cross-validation yourself; it is actually fairly straightforward. The following code does roughly the same thing as Scikit-Learn's cross_val_score() function, and prints the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532\n",
      "0.95125\n",
      "0.9625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3, random_state = 42) # nsplits = 3 --> 3fold CV\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    # get fresh copy of predictor\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    \"\"\"\n",
    "    from clone doc\n",
    "    \n",
    "    Constructs a new estimator with the same parameters.\n",
    "\n",
    "    Clone does a deep copy of the model in an estimator without actually copying attached data. \n",
    "    It yields a new estimator with the same parameters that has not been fit on any data.\n",
    "    \"\"\"\n",
    "    # set training and testing subset iteration\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    # fit predictor for iteration\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StratifiedKFold class performs stratified sampling to produce folds that contain representative ratio of each class. At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predictions on the test fold. Then it counts the number of correct predictions and outputs the ratio of correct predictions.\n",
    "\n",
    "Let's use the cross_val_score() function to evaluate your SGDClassifier model using K-fold cross-validation, with three folds. Remember that K-fold cross-validation means splitting the training set into K-folds (in this case, three), then making predictions and evaluating them on each fold using a model trained on the remaining folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9532 , 0.95125, 0.9625 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 95% *accuracy* (ratio of correct predictions) on all cross-validation folds? This looks amazing, doesn't it? Well, before you get too excited, let's look at a very dumb classifier that just classifies every single image in the \"not-5\" class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    # do nothing for fit\n",
    "    def fit(self, X, y = None):\n",
    "        pass\n",
    "    # predict everything as false\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype = bool)\n",
    "# can you guess this model's accuracy? Let's find out:\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, it has over 90% accuracy! This is simply because only about 10% of the images are 5s, so if you always guess that an image in *not* a 5, you will be right about 90% of the time.\n",
    "\n",
    "This demonstrates why accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with *skewed datasets* (i.e. when some classes are much more frequent than others).\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the *confusion matrix*.\n",
    "The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5th row and the 3rd column of the confusion matrix.\n",
    "\n",
    "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You coul make predictions on the test set, but let's keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch).\n",
    "Instead, you can  use the cross_val_predict() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the (mean) evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (\"clean\" meaning that the prediction is made by a model that never saw the data during training).\n",
    "\n",
    "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52992,  1587],\n",
       "       [ 1074,  4347]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an *actual class*, while each column represents a *predicted class*. The first row of this matrix considers non-5 images (the *negative class*): 52992 were predicted correctly as non-5 images (TRUE NEGATIVES), while the remaining 1587 were wrongly classified as 5s (FALSE POSITIVES). The second row considers the images of 5s (the *positive class*): 1074 were wrongly classified as non-5s (FALSE NEGATIVES), while the remaining 4347 were correctly classified as 5s (TRUE POSITIVES). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_perfect_predictions = y_train_5 # pretend we reached perfection\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise metric. An interesting one to look is the accuracy of the positive predictions; this is called the *precision* of the classifier: precision = TP /(TP + FP)\n",
    "\n",
    "A trivial way to have perfect precision is to make one single positive prediction and ensure it is correct (precision = 1/1 = 100%). This would not be very useful since the classifier would ignore all but one positive instance. So precision is typicallyused along with another metric named *recall*, also called *sensitivity* or *true positive rate*: recall = TP / (TP + FN)\n",
    "\n",
    "### Precision and Recall\n",
    "\n",
    "Scikit-Learn provides several functions to compute classifier metrics, including precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7325581395348837\n",
      "0.8018815716657444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(precision_score(y_train_5, y_train_pred))\n",
    "print(recall_score(y_train_5, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your 5-detector does not look as shiny as it did when you looked at its accuracy. When it claims an image represents a 5, it is correct only 73% of the time. Moreover, it only detects 80% of the 5s.\n",
    "\n",
    "It is often convenient to combine precision and recall into a single metric called the F1 score, in particular if you need a simple way to compare two classifiers. The F1 score is the *harmonic mean* of precision and recall. Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high.\n",
    "F1 = 2 x (precision x recall)/(precision + recall)\n",
    "\n",
    "To compute the F1 score, simply call the f1_score() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765653896961691"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score favors classifiers that have similar precision and recall. This is not always what you want: in some contexts you mostly care about precision, and in other contexts you really care about recall.\n",
    "\n",
    "For example if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases you may even want to add a human pipeline to check the classifier's video selection). \n",
    "\n",
    "On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get caught).\n",
    "\n",
    "Unfortunately, you can't have it both ways: increasing precision reduces recall, and vice versa. This is called the *precision/recall tradeoff*.\n",
    "\n",
    "### Precision/Recall Tradeoff\n",
    "\n",
    "To understand this tradeoff, let's look at how the SGDClassifier makes its classification decisions. For each instance, it computes a score based on a *decision function*, and if that score is greater than a threshold it assigns the instance to the positive class, or else it assigns it to the negative class.\n",
    "\n",
    "Moving this decision threshold* we can control the precision/recall tradeoff.\n",
    "\n",
    "Scikit-Learn does not let you set the threshold directly, but it does give you access to the decision scores that it uses to make predictions. Instead of calling the classifier predict() method, you can call its decision_function() method, which returns a score for each instance, and then make predictions based on those scores using any threshold you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-45148.19955869]\n",
      "[False]\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "print(y_scores)\n",
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "print(y_some_digit_pred)\n",
    "\"\"\"\n",
    "The SGDClassifier uses a threshold equal to 0, \n",
    "so the previous code returns the same result as the predict() method (i.e. False).\n",
    "Let's lower the threshold\n",
    "\"\"\"\n",
    "threshold = -50000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "print(y_some_digit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how do you decide which threshold to use? For this you will first need to get the scores of all instances in the training set using the cross_val_predict() function again, but this time specifying that you want it to return decision scores instead of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3, method = \"decision_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with these scores you can compute precision and recall for all possible thresholds using the precision_recall_curve() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\"\"\"\n",
    "Finally, you can plot precision and recall as functions of the threshold value using Matplotlib\n",
    "\"\"\"\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n",
    "    plt.plot(recalls[:-1], \"g-\", label = \"Recall\")\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder why the precision curve is bumpier than the recall curve. The reason is that precision may sometimes go down when you raise the threshold (although in general it will go up). On the other hand, recall can only go down when the threshold is increased, which explains why its curve looks smooth.\n",
    "\n",
    "## PAG 97\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
