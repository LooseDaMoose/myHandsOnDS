{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Introduction to Artificial Neural Networks with Keras\n",
    "   \n",
    "## From Biological to Artificial Neurons\n",
    "\n",
    "Artificial Neural Networks were inspired by biological neurons. First introduced back in 1943, but entered a long winter as other methods worked better. We are now witnessing another wave of interest in ANNs. This time, there are a few good reasons to believe that this wave is different and that it will have a much more profound impact on our lives:\n",
    "\n",
    "- There is now a huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    "- The tremendous increase in computing power since the 1990s now makes it possible to train large neural networks in a reasonable amount of time. This is in part due to Moore's Law, but also thanks to the gaming industry, which has produced powerful GPU cards by the millions.\n",
    "- The training algos have been improved. To be fair they are only slighly different from the ones used in the 1990s, but these relatively small tweaks have a huge positive impact.\n",
    "- Some theoretical limitations of ANNs have turned out to be benign in practice. For example, many people thought that ANN training algos were doomed because they were likely to get stuck in local optima, but it turns out that this is rather rare in practice (or when it is the case, they are usually fairly close to the global optimum).\n",
    "- ANNs seem to have entered a virtuous circle of funding and progress. Amazing products based on ANNs regularly make the headline news, which pulls more and more attention and funding towards them, resulting in more and more progress, and even more amazing products.\n",
    "\n",
    "## Biological Neurons\n",
    "\n",
    "Before discussing artificial neurons, let's take a quick look at a biological neuron. It is an unusual-looking cell mostly found in animal cerebral cortexes, composed of a *cell body* containing the nucleus and most of the cell's complex components, and many branching extensions called *dendrites*, plus one very long extension called the *axon*. The axon's length may be just a few times longer than the cell body, or up to tens of thousands of times longer. Near its extremity the axon splits off into many branches called *telodendria*, and at the tip of these branches are minuscule structures called *synaptic terminals* (or simply *synapses*), which are connected to the dendrites (or directly to the cell body) of other neurons. Biological neurons receive short electrical impluses called *signals* from other neurons via these synapes. When a neuron receives a sufficient number of signals from other neurons within a few milliseconds, it fires its own signals.\n",
    "\n",
    "![alt text](neuron.PNG \"bio neuron\")\n",
    "\n",
    "Thus, individual biological neurons seem to behave in a rather simple way, but they are organized in a vast network of billions of neurons, each neuron typically connected to thousands of other neurons. Highly complex computations can be performed by a vast network of fairly simple neurons, much like a complex anthill can emerge from the combined efforts of simple ants. The architecture of biological neural networks is still the subject of active research, but some parts of the brain have been mapped, and it seems that neurons are often organized in consecutive layers.\n",
    "\n",
    "## Logical Computations with Neurons\n",
    "\n",
    "McCulloch and Pitts proposed a very simple model of the biological neuron, which later became known as an *artificial neuron*: it has one or more binary (on/off) inputs and one binary output. The artificial neuron simply activates its output when more than a certain number of its inputs are active. They showed that even with such a simplified model it is possible to build a network of artificial neurons that computes any logical proposition you want.\n",
    "\n",
    "## The Perceptron\n",
    "\n",
    "The *Perceptron* is one of the simplest ANN architecturesm invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a *threshold logic unit* (TLU), or sometimes a *linear threshold unit* (LTU): the inputs and output are now numbers rather than binary on/off values and each input connection is associated with a weight. The TLU computes a weighted sum of its inputs ($z = w_1x_1 + w_2x_2 + ... + w_nx_n = x^tw$), then applies a *step function* to that sum and outputs the results: $h_w(x) = step(z)$ , where $z = x^tw$.\n",
    "\n",
    "![alt text](TLU.PNG \"TLU\")\n",
    "\n",
    "\n",
    "A single TLU can be used for simple linear binary classification. It computes a linear combination of the inputs and if the result exceeds a threshold, it outputs the positive class or else outputs the negative class (just like a Logistic Regression classifier or a linear SVM). \n",
    "\n",
    "A Perceptron is simply composed of a single layer of TLUs, with each TLU connected to all the inputs. When all the neurons in a layer are connected to every neuron in the previous layers (i.e., its input neurons), it is called a *fully connected* layer or a *dense leyaer*. To represent the fact that each input is sent to every TLU, it is common to draw special passthrough neurons called *input neurons*: they just output whatever input they are fed. All the input neurons form the *input layer*. Moreover, an extra bias feature is generally added ($x_0 = 1$): it is typically represented using a special type of neuron called a *bias neuron*, which just outputs 1 all the time. \n",
    "A Perceptron with two inputs and three outputs is represented below.\n",
    "\n",
    "![alt text](perceptron.PNG \"perceptron\")\n",
    "\n",
    "This Perceptron can classify instances simultaneously into three different binary classes, which makes it a multioutput classifier.\n",
    "\n",
    "Thanks to the magic of linear algebra, it is possible to efficiently compute the outputs of a layer of artificial neurons for several instances at once by using the equation below:\n",
    "\n",
    "$$ h_{W,b}(X) = \\phi(XW + b)$$\n",
    "\n",
    "- As always, X represents the matrix of input features. It has one row per instance, one column per feature.\n",
    "- The weight matrix W contains all the connection weights except for the ones from the bias neuron. It has one row per input neuron and one column per artifical neuron in the layer.\n",
    "- The bias vector b contains all the connection weights between the bias neuron and the artificial neurons. It has one bias term per artificial neuron.\n",
    "- The function $\\phi$ is called the *activation function*: when the artificial neurons are TLUs, it is a step function (but we will discuss other activation functions shortly).\n",
    "\n",
    "So how is a Perceptron trained? The Perceptron training algo proposed was largely inspired by *Hebb's rule* (when a biological neuron often triggers another neuron, the connection between these two neurons grows stronger or \"Cells that fire together, wire together\"). The connection weight between two neurons is increased whenever they have the same output. Perceptrons are trained using a variant of this rule that takes into account the error made by the netwkork; it reinforces connections that help reduce the error. More specifically, the Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed the correct prediction. The rule is shown in the equation below:\n",
    "\n",
    "$$ w_{i,j}^{(next step)} = w_{i,j} + \\eta(y_j - \\hat{y_j})x_i $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ w_{i,j}$ is the connection weight between the $i^{th}$ input neuron and the $j^{th}$ output neuron.\n",
    "- $x_i$ is the $i^{th}$ input value of the current training instance.\n",
    "- $\\hat{y_j}$ is the output of the $j^{th}$ output neuron for the current training instance.\n",
    "- $\\eta$ is the learning rate.\n",
    "\n",
    "The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like Logistic Regression classifiers). However, if the training instances are linearly separable, it was demonstrated that this algo would converge to a solution. This is called the *Perceptron convergence theorem*.\n",
    "\n",
    "Scikit-Learn provides a `Perceptron` class that implements a single TLU network. It can be used pretty much as you would expect.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\levka\\Anaconda3\\envs\\ds001\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,(2,3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa? 0 or 1\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X,y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the fact that the Perceptron learning algo strongly resembles Stochastic Gradient Descent. In fact, Scikit-Learn's `Perceptron` class is equivalent to using a `SGDClassifier` with the following hyperparameters: `loss=\"perceptron\"`,`learning_rate=\"constant\"`,`eta0=1` (the learning rate), and `penalty=None` (no regularization).\n",
    "\n",
    "Note that contrary to Logistic Regression classifiers, Perceptrons do not output a class probability; rather, they just make predictions based on a hard threshold. This is one of the good reasons to prefer Logistic Regression over Perceptrons.\n",
    "\n",
    "In the 1969 monograph titled *Perceptrons*, a number of serious weaknesses of Perceptrons were highlighed, in particular the fact that they are incapable of solving some trivial problems (e.g. the *Exclusive OR (XOR)* classification problem. \n",
    "\n",
    "However, it turns out that some of the limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting ANN is called a *Multi-Layer Perceptron* (MLP). \n",
    "\n",
    "## Multi-Layer Perceptron and Backpropagation\n",
    "\n",
    "An MLP is composed of one (passtrhough) *input layer*, one or more layers of TLUs called *hidden layers*, and one final layer of TLUs called the *output layer* (see figure below). The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
    "\n",
    "![alt text](MLP.PNG \"MLP\")\n",
    "\n",
    "**Note**:\n",
    "\n",
    "The signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a *feedforward neural network* (FNN).\n",
    "\n",
    "When an ANN contains a deep stack of hidden layers, it is called a *deep neuroal network* (DNN). The field of Deep Learning studies DNNs, and more generally models containing deep stacks of computations. However, many people talk about Deep Learning whenever neural networks are involved (even shallow ones).\n",
    "\n",
    "For many years researchers struggled to find a way to train MLPs, without success. In 1986 a groundbreaking paper was published introducing the *backpropagation* training algorithm, which is still used today. In short, it is simply Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network's error with regards to every single model parameter. In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular Gradient Descent step, and the whole process is repeated until the network converges to the solution.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Automatically computing gradients is called *automatic differentiation*, or autodiff. There are various autodiff techniques, with different pros and cons. The one used by backpropagation is called *reverse-mode autodiff*. It is fast and precise, and is well suited when the function to differentiate has many variables (e.g. connection weights) and few outputs (e.g. one loss).\n",
    "\n",
    "Let's run through this algo in a bit more detal:\n",
    "\n",
    "- It handles one mini-batch at a time (for example containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an *epoch*.\n",
    "- Each mini-batch is passed to the network's input layer, which just sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the *forward pass*: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "- Next the algo measures the network's output error (i.e. it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
    "- Then it computes how much each output connection contributed to the error. This is done analytically by simply applying the *chainrule*, which makes this step fast and precise.\n",
    "- The algo then measures how much of these error contributions came from each connection in the layer below, again using the chain rule -- and so on until the algo reaches the input layer. As we explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the neame of the algorithm).\n",
    "- Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the nextwork, using the error gradients it just computed.\n",
    "\n",
    "This algo is so important, it's worth summarizing again: for each training instance the backprop algo first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each conection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "**Caution**:\n",
    "\n",
    "It is important to initialize all the hidden layers' connection weights randomly, or else training will fail. For example, if you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical. In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it won't be too smart. If instead you randomly initialize the weights, you *break the symmetry* and allow backpropagation to train a diverse team of neurons.\n",
    "\n",
    "In order for this algo to work properly, the authors made a key change to the MLP's architecture: they replaced the step function with the logistic function, $\\sigma(z) = 1 / (1 + exp(-z))$. This was essential because the step function contains only flat segments, so there is no gradient to work with (Gradient Descent cannot move on a flat surface), while the logistic function has a well-defined nonzero derivative everywehre, allowing Gradient Descent to make some progress at every step. In fact, the backpropagation algorithm works well with many other *activation functions*, not just the logistic function. Two other popular activation function are:\n",
    "\n",
    "*The hyperbolic tangent function:* $ tan(z) = 2\\sigma(2z)-1$\n",
    "\n",
    "Just like the logistic function it is S-shaped, continuous, and differentiable, but its output value ranges from -1 to 1 (instead of 0 to 1), which tends to make each layer's output more or less centered aroung 0 at the beginning of training. This often helps speed up convergence.\n",
    "\n",
    "*The Rectified Linear Unit function:* $ReLU(z) = max(0,z)$\n",
    "\n",
    "It is continuous but unfortunately not differentiable at z = 0 (the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for z < 0. However, in practice it works very well and has the advantage of being fast to compute. Most importantly, the fact that it does not have a maximum output value also helps reduce some issues during Gradient Descent.\n",
    "\n",
    "These popular activation functions and their derivatives are represented in the figure below.\n",
    "\n",
    "Why do we need activation functions in the first place? Well, if you chain several linear transformations, all you get is a linear transformation. For example, say $f(x) = 2x + 3$ and $g(x) = 5x - 1$, then chaining these two linear functions gives you another linear function: $f(g(x)) = 2(5x -1) + 3 = 10x +1$. So if you don't have some non-linearity between layers, then even a deep stack of layers is equivalent to a single layer: you cannot solve very complex problems with that.\n",
    "\n",
    "\n",
    "![alt text](activationfuns.PNG \"activationfuns\")\n",
    "\n",
    "\n",
    "But what can we do with them?\n",
    "\n",
    "# Regression MLPs\n",
    "\n",
    "First, MLPs can be used for regression tasks. If you want to predict a single value (e.g. the price of a house given many of its features), then you just need a single output neuron: its output is the predicted value. For multivariate regression (i.e. to predict multiple values at once), you need one output neuron per output dimension. For example, to locate the center on an image, you need to predict 2D coordinates, so you need two output neurons. If you also want to place a bounding box around the object, then you need two more number: the width and the height of the object. So you end up with 4 output neurons.\n",
    "\n",
    "In general, when building an MLP for regression, you do not want to use any activation function for the output neurons, so they are free to output any range of values. However, if you want to guarantee that the output will always be positive, then you can use the ReLU activation function, or the *softplus* activation function in the output layer. Finally, if you want to guarantee that the predictions will fall within a give range of values, then you can use the logistic function or the hyperbolic tangent, and scale the labels to the appropriate range: 0 to 1 for the logistic, or -1 to 1 for the hyperbolic tangent.\n",
    "\n",
    "The loss function to use during training is typically the mean squared error, but if you have a lot of outliers in the training set, you may prefer to use the mean absolute error instead. Alternatively, you can use the Huber loss, which is a combination of both.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "The Huber loss is quadratic when the error is smaller than a threshold $\\delta$ (typically 1), but linear when the error is larger than $\\delta$. This makes it less sensitive to outliers than the mean squared error, and it is often more precise and converges faster than the mean absolute error.\n",
    "\n",
    "Typical Regression MLP Architecture:\n",
    "\n",
    "|Hyperparameter| Typical Value|\n",
    "|--------------|--------------|\n",
    "|# input neurons| One per input feature (e.g., 28 x 28 = 784 for MNIST)|\n",
    "|# hidden layers| Depends on the problem. Typically 1 to 5.|\n",
    "|# neurons per hidden layer |Depends on the problem. Typically 10 to 100.|\n",
    "|# output neurons| 1 per prediction dimension|\n",
    "|Hidden activation| ReLU (or SELU, see Chapter 11)|\n",
    "|Output activation| None or ReLU/Softplus (if positive outputs) or Logistic/Tanh (if bounded outputs)|\n",
    "|Loss function| MSE or MAE/Huber (if outliers)|\n",
    "\n",
    "# Classification MLPs\n",
    "\n",
    "MLPs can also be used for classification tasks. For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class. Obviously, the estimated probability of the negative class is equal to one minus that number.\n",
    "\n",
    "MLPs can also easily handle multilabel binary classification tasks. For example, you could have an email classification system that predicts whether each incoming email is ham or spam, and simultaneously predicts whether it is an urgent or non-urgent email. In this case, you would need two output neurons, both using the logistic activation function: the first would output the probabiity that the email is spam and the second would output the probability that it is urgent. More generally, you would dedicate one output neuron for each positive class. Note that the output probabilities do not necessarily add up to one. This lets the model output any combination of labels: you can have non-urgent ham, urgent ham, non-urgent spam, and perhaps even urgent spam.\n",
    "\n",
    "If each instance can belong only to a single class, out of 3 or more possible classes (e.g. classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the *softmax* activation function for the whole output layer (see figure below). The softmax function will ensure that all the estimated probabilities are between 0 and 1 and that they add up to one (which is required if the classes are exclusive). This is called multiclass classification.\n",
    "\n",
    "![alt text](class.PNG \"class\")\n",
    "\n",
    "Regarding the loss function, since we are predicting probability distributions, the cross-entropy (also called the log loss) is generally a good choice.\n",
    "\n",
    "Typical Classification MLP Architecture\n",
    "\n",
    "\n",
    "|Hyperparameter |Binary classification| Multilabel binary classification| Multiclass classification|\n",
    "|---------------|---------------------|---------------------------------|--------------------------|\n",
    "|Input and hidden layers| Same as regression| Same as regression| Same as regression|\n",
    "|# output neurons| 1 |1 per label| 1 per class|\n",
    "|Output layer activation| Logistic| Logistic| Softmax|\n",
    "|Loss function| Cross-Entropy| Cross-Entropy| Cross-Entropy|\n",
    "\n",
    "# Implementing MLPs with Keras\n",
    "\n",
    "Keras is a high-level Deep Learning API that allows you to easily build, train, evaluate and execute all sorts of neural networks. TensorFlow now comes bundled with its own Keras implementation called tf.keras. It only supports TensorFlow as the backend, but it has the advantage of offering some very useful extra features. For this reason, we will use tf.keras in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API\n",
    "\n",
    "First, we need to load a dataset. We will tackle *Fashion MNIST*, which is a drop-in replacement of MNIST. It has the exact same format as MNIST, but the images represent fashion items rather than handwritten digits, so each class is more diverse and the problem turns out to be significantly more challenging than MNIST. For example, a simple linear model reaches 92% accuracy on MNIST, but only about 83% on Fashion MNIST.\n",
    "\n",
    "### Using Keras to Load the Dataset\n",
    "\n",
    "Keras provides some utility functions to fetch and load common datasets, including MNIST, Fashion MNIST, the original California housing dataset, and more. Let's load Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading MNIST or Fashion MNIST using Keras rather than Scikit-Learn, one important difference is that every image is represented as a 29x29 array rather than a 1D array of size 784. Moreover, the pixel intensities are represented as integers (0 - 255) rather than floats (0.0 to 255.0). Here is the shape and data type of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataset is already split into a training set and a test set, but there is no validation set, so let's create one. Moreover, since we are going to train the neural network using Gradient Descent, we must scale the input features. For simplicity, we just scale the pixel intensitiesdown to the 0-1 range by dividing them by 255.0 (this also converts them to floats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With MNIST, when the label is equal to 5, it means that the image represents the handwritten digit 5. Easy. However, for Fashion MNIST, we need the list of class names to know what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model Using the Sequential API\n",
    "\n",
    "Now let's build the neural network. Here is a classification MLP with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 11:32:15.065183 13840 deprecation.py:506] From C:\\Users\\levka\\Anaconda3\\envs\\ds001\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' go through this code line by line:\n",
    "\n",
    "- The first line creates a `Sequential` model. This is the simplest kind of Keras model, for neural networks that are just composed of a single stack of layers, connected sequentially. This is called the sequential API.\n",
    "- Next, we build the first layer and add it to the model. It is a `Flatten` layer whose role is simply to convert each input image into a 1D array: if it receives input data X, it computes X.reshape(-1,1). This layer does not have any parameters., it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape`: this does not include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `shape=[28,28]`\n",
    "- Next we add a `Dense` hidden layer with 300 neurons. It will use the ReLU activation function. Each `Dense` layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes $ h_{W,b}(X) = \\phi(XW + b)$.\n",
    "- Next we add a second `Dense` hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "- Finally, we add a `Dense` output layer with 10 neurons (one per class) using the softmax activation function (because the classes are exclusive).\n",
    "\n",
    "Instead of adding the layers one by one as we did, you can pass a list of layers when creating the `Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's `summary()` method displays the model's layers, including each layer's name (which is automatically generated unless you set it when creating the layer), its output shape (`None` means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Dense` layers often have a lot of parameters. This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data. \n",
    "\n",
    "You can easily get a model's list of layers, to fetch a layer by its index, or you can fetch it by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x18f66464b38>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18f66464470>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18f795c72e8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18f795fc390>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3').name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can be accessed using its `get_weights()` and `set_weights()` method. For a `Dense` layer, this includes both the connection weights and the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01700069, -0.04908524,  0.03225771, ..., -0.04404444,\n",
       "        -0.03663135,  0.04914783],\n",
       "       [-0.0300201 , -0.06689911,  0.04994996, ..., -0.01440933,\n",
       "        -0.01641243,  0.00577749],\n",
       "       [-0.05439606, -0.07156505, -0.05489115, ...,  0.01903838,\n",
       "         0.02121542,  0.04227027],\n",
       "       ...,\n",
       "       [-0.05269217, -0.04640948, -0.07064886, ..., -0.04474382,\n",
       "         0.03409272,  0.01258345],\n",
       "       [ 0.06512965,  0.06660137, -0.04716873, ...,  0.0360424 ,\n",
       "         0.06164545,  0.00366428],\n",
       "       [-0.01184493, -0.0330516 ,  0.03280292, ...,  0.06456792,\n",
       "         0.00195263, -0.07023211]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `Dense` layer initialized the connection weights randomly (which is needed to break symmetry, as we discussed earlier), and the biases were just initialized to zeros, which is fine. If yo ever want to use a diffrent initialization method, you can set `kernel_initializer` (*kernel* is another name for the matrix of connection weights) or `bias_initializer` when creating the layer.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "The shape of the weight matrix depends on the number of inputs. This is why it is recommended to specify the `input_shape` when creating the first layer in a `Sequential` model. However, if you do not specify the input shape, it's okay: Keras will simply wait until it knows the input shape before it actually builds the model This will happen either when you feed it actual data (e.g. during training), or when you call its `build()` method. Until the model is really build, the layers will not have any weights, and you will not be able to do certain things (such as print the model summary or save the model), so if you know the input shape when creating the model, it is best to specify it.\n",
    "\n",
    "### Compiling the Model\n",
    "\n",
    "After a model is created, you must call its `compile()` method to specify the loss function and the optimizer to use. Optionally, you can also specify a list o f extra metrics to compute during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires some explanation. First, we use the `sparse_categorical_crossentropy` loss because we have sparse labels (i.e. for each instance there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors), then we would need to use the `\"categorical_crossentropy\"` loss instead. If we were doing binary classification (with one or more binary labels), then we would use the `\"sigmoid\"` activation function in the output layer instead of the `\"softmax\"` activation function, and we would use the `\"binary_crossentropy\"` loss.\n",
    "\n",
    "Secondly, regarding the optimizer, `\"sgd\"` simply means that we will train the model using simple Stochastic Gradient Descent. \n",
    "\n",
    "Finally, since this is a classifier, it's useful to measure its `\"accuracy\"` during training and evaluation.\n",
    "\n",
    "### Training and Evaluating the Model\n",
    "\n",
    "Now the model is ready to be trained. For this we simply need to call its `fit()` method. We pass it the input features `(X_train)` and the target classes `(y_train)`, as well as the number of epochs to train. We also pass a validation set (this is optional): Keras will measure the loss and the extra metrics on this set at the end of each epoch, which is very useful to see how well the model really performs: if the performance on the training set is much better than on the validation set, your model is probably overfitting the training set (or there is a bug, such as a data mismatch between the training set and the validation set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.7280 - acc: 0.7613 - val_loss: 0.5112 - val_acc: 0.8254\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.4904 - acc: 0.8290 - val_loss: 0.4437 - val_acc: 0.8484\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.4444 - acc: 0.8446 - val_loss: 0.4428 - val_acc: 0.8550\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.4169 - acc: 0.8544 - val_loss: 0.3964 - val_acc: 0.8668\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.3969 - acc: 0.8598 - val_loss: 0.3988 - val_acc: 0.8600\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3795 - acc: 0.8661 - val_loss: 0.3737 - val_acc: 0.8692\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.3662 - acc: 0.8711 - val_loss: 0.3607 - val_acc: 0.8758\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.3552 - acc: 0.8742 - val_loss: 0.3657 - val_acc: 0.8728\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3443 - acc: 0.8775 - val_loss: 0.3482 - val_acc: 0.8782\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.3335 - acc: 0.8823 - val_loss: 0.3538 - val_acc: 0.8752\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.3249 - acc: 0.8837 - val_loss: 0.3505 - val_acc: 0.8744\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.3179 - acc: 0.8864 - val_loss: 0.3309 - val_acc: 0.8820\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3099 - acc: 0.8876 - val_loss: 0.3284 - val_acc: 0.8838\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3030 - acc: 0.8911 - val_loss: 0.3326 - val_acc: 0.8834\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2975 - acc: 0.8927 - val_loss: 0.3138 - val_acc: 0.8880\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.2906 - acc: 0.8949 - val_loss: 0.3106 - val_acc: 0.8896\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2841 - acc: 0.8983 - val_loss: 0.3187 - val_acc: 0.8868\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2788 - acc: 0.8985 - val_loss: 0.3283 - val_acc: 0.8824\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.2738 - acc: 0.9016 - val_loss: 0.3263 - val_acc: 0.8778\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.2685 - acc: 0.9040 - val_loss: 0.3276 - val_acc: 0.8830\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2632 - acc: 0.9062 - val_loss: 0.3395 - val_acc: 0.8806\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.2586 - acc: 0.9065 - val_loss: 0.3064 - val_acc: 0.8878\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.2549 - acc: 0.9072 - val_loss: 0.3055 - val_acc: 0.8864\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2505 - acc: 0.9087 - val_loss: 0.2975 - val_acc: 0.8920\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.2456 - acc: 0.9115 - val_loss: 0.2968 - val_acc: 0.8928\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2418 - acc: 0.9129 - val_loss: 0.3043 - val_acc: 0.8882\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.2375 - acc: 0.9138 - val_loss: 0.2992 - val_acc: 0.8902\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.2332 - acc: 0.9157 - val_loss: 0.2960 - val_acc: 0.8902\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.2304 - acc: 0.9164 - val_loss: 0.2902 - val_acc: 0.8956\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2270 - acc: 0.9167 - val_loss: 0.3073 - val_acc: 0.8868\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, the neural network is trained. At each epoch during training, Keras displays the number of instances processed so far (along with a progress bar), the mean training time per sample, the loss and accuracy (or any other extra metrics you asked for), both on the training set and the validation set. You can see that the training loss went down, which is a good sign, and the validation accuracy reached 89% after 30 epochs, not too far from the training accuracy, so there does not seem to be much overfitting going on.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Instead of passing a validation set using the `validation_data` argument, you could instead set `validation_split` to the ratio of the training set that you want Keras to use for validation (e.g. 0.1).\n",
    "\n",
    "If the training set was very skewed, with some classes being overrepresented and others underrepresented, it would be useful to set hte `class_weight` argument when calling the `fit()` method, giving a larger weight to underrepresented classes, and a lower weight to overrepresented classes. These weights would be used by Keras when computing the loss. If you need per-instance weights instead, you can set the `sample_weight` argument (it supersedes `class_weight`). This could be useful for example if some instances were labeled by experts while others were labeled using a crowdsourcing platform: you might want to give more weight to the former. You can also provide sample weights (but not class weights) for the validation set by adding them as a third item in the `validation_data` tuple. \n",
    "\n",
    "The `fit()` method returns a `History` object containing the training parameters (`history.params`), the list of epochs it went through (`history.epoch`), and most importantly a dictionary (`history.history`) containing the loss and extra metrics it measured at the end of each epoch on the training set and on he validation set (if any). If you create a Pandas DataFrame using this dictionary and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both the training and validation accuracy steadily increase during training, while the training and validation loss decrease. Moreover, the validation curves are quite close to the training curves, which means that there is not too much overfitting. In this particular case, the model performed better on the validation set than on the training set at the beginning of training: this sometimes happens by chance (especially when the validation set is fairly small). However, the training set performance ends up beating the validation performance, as is generally the case when you train for long enough. You can tell that the model has not quite converged yet, as the validation loss is still going down, so you should probably continue training. It's as simple as calling the `fit()` method again, since Keras just continues training where it left off.\n",
    "\n",
    "If you are not satisfied with the performance of your model, you should go back and tune the model's hyperparameters, for example the number of layers, the number of neurons per layer, the types of activation functions we use for each hidden layer, the number of training epochs, the batch size (it can be set in the `fir()` method using the `batch_size` argument, which defaults to 32). \n",
    "\n",
    "Once you are satisfied with your model's validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deplou the model to production. You can easily do this using the `evaluate()` method (it also supports several other arguments, such as `batch_size` or `sample_weight`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/sample - loss: 53.2413 - acc: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[53.24129517326355, 0.8655]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to get slightly lower performance on the test set than on the validation set, because the hyperparameters are tuned on the validation set, not the test set. Remember to resist the temptation to tweak the hyperparameters on the test set, or else your estimate of the generalization error will be too optimistic.\n",
    "\n",
    "### Using the Model to Make Predictions\n",
    "\n",
    "Next, we can use the model's `predict()` method to make predictions on new instances. Since we don't have actual new instances, we will just use the first 3 instances of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see for each instance the model estimates one probability per class, from class 0 to class 9. If you only care about the class with the highest estimated probability (even if the prob is quite low) then you can use the `predict_classes()` method instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the classifier actually classified all three images correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to build, train, evaluate and use a classification MLP using the sequential API. But what about regression?\n",
    "\n",
    "## Building a Regression MLP Using the Sequential API\n",
    "\n",
    "Let's switch to the California housing problem and tackle it using a regression neural network. For simplicity, we will use Scikit-Learn's `fetch_california_housing()` function to load the data: this dataset is simpler than the one used in chapter 2 since it contains only numerical features and there is no missing value. After loading the data, we split it into training set, a validation set and a test set, and we scale all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.fit_transform(X_valid)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building, training, evaluating and using a regression MLP using the Sequential API to make predictions is quite similar to what we did for classification. The main differences are the fact that the output layer has a single neuron (since we only want to predict a single value) and uses no activation function, and the loss function is the mean squared error. Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7445 - val_loss: 0.5494\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5126 - val_loss: 0.4831\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4681 - val_loss: 0.5053\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4719 - val_loss: 0.5260\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4369 - val_loss: 0.6099\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5795 - val_loss: 0.7962\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4079 - val_loss: 0.8765\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3959 - val_loss: 0.9985\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3915 - val_loss: 1.0611\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3873 - val_loss: 1.1267\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3813 - val_loss: 1.2561\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3801 - val_loss: 1.3004\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3758 - val_loss: 1.3371\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3728 - val_loss: 1.4580\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3726 - val_loss: 1.6003\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3689 - val_loss: 1.6850\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3652 - val_loss: 1.7311\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3643 - val_loss: 1.7749\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3622 - val_loss: 1.8698\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3614 - val_loss: 1.9272\n",
      "5160/5160 [==============================] - 0s 14us/sample - loss: 0.4318\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss = \"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20,\n",
    "                   validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.4318\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68670493],\n",
       "       [2.383072  ],\n",
       "       [1.4777709 ],\n",
       "       ...,\n",
       "       [1.8684225 ],\n",
       "       [2.350346  ],\n",
       "       [1.2349541 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test_scaled[3:]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Sequential API is quite easy to use. However, altough sequential models are extremely common, it is sometimes useful to build NN with more complex topologies, or with multiple inputs or outputs. For this purpose, Keras offers the Functional API.\n",
    "\n",
    "## Building Complex Models Using the Functional API\n",
    "\n",
    "One example of a non-sequential neural network is a *Wide & Deep* Neural network. This NN architecture was introduce in a 2016; it connects all or part of the inputs directly to the output layer, as shown in the figure below. This architecture makes it possible for the NN to learn both deep patterns (using the deep path) and simple rules (trough the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers, thus simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "![](widendeep.PNG \"wnd\")\n",
    "\n",
    "Let's build such a NN to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    nninput = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(30, activation=\"relu\")(nninput)\n",
    "    hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "    concat = keras.layers.Concatenate()([nninput, hidden2])\n",
    "    nnoutput = keras.layers.Dense(1)(concat)\n",
    "    model = keras.models.Model(inputs=[nninput], outputs=[nnoutput])\n",
    "    model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "    return model\n",
    "        \n",
    "        \n",
    "\n",
    "model = createmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through each line of this code:\n",
    "\n",
    "- FIrst, we need to create an `Input` object. This is needed because we my have multiple inputs, as we will see later.\n",
    "\n",
    "- Next, we create a `Dense` layer with 30 neurons and using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together, no actual data is being processe yet.\n",
    "\n",
    "- We then create a second hidden layer, and again we use it as a function. Note however that we pass it the output of the first hidden layer.\n",
    "\n",
    "- Next, we create a `Concatenate()` layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer (you may prefer the `keras.layers.concatenate()` function, which creates a `Concatenate` layer and immediately calls it with the given inputs).\n",
    "\n",
    "- Then we create the output layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
    "\n",
    "- Lastly, we create a `Keras Model`, specifying which inputs and outputs to use.\n",
    "\n",
    "Once you have built the Keras model, everything is exactly like earlier, so no need to repeat it there: compile, train, evaulate and use the model to make predictions.\n",
    "\n",
    "But what if you want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path (see figure below)? In this case, one solution is to use multiple inputs. For example, suppose we want to send 5 features through the deep path (features 0 to 4), and 6 features through the wide path (features 2 to 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5])\n",
    "input_b = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_a, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_a, input_b], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](widendeep2.PNG \"\")\n",
    "\n",
    "The code is self-explanatory. Note that we specified `inputs=[input_a, input_b]` when creating the model. Nowe we can compile the model as usual, but when we call the `fit()` method, instead of passing a single input matrix `X_train`, we must pass a tuple of matrices `(X_train_a, X_train_b)`:  one per input. The same is true for `X_valid`, and also for `X_test`, and `X_new` when you call `evaluate()` or `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.7814 - val_loss: 0.6529\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4770 - val_loss: 0.9749\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4579 - val_loss: 0.8093\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4217 - val_loss: 0.8371\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4127 - val_loss: 0.9972\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4104 - val_loss: 1.1143\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3979 - val_loss: 1.2609\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3989 - val_loss: 1.2424\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4014 - val_loss: 1.4488\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3841 - val_loss: 1.5820\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3784 - val_loss: 1.6697\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3800 - val_loss: 1.6947\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3825 - val_loss: 1.9150\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4262 - val_loss: 1.8098\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3747 - val_loss: 2.1322\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3631 - val_loss: 2.2073\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3602 - val_loss: 2.1036\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3587 - val_loss: 2.3060\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3541 - val_loss: 2.2126\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3506 - val_loss: 2.5213\n",
      "5160/5160 [==============================] - 0s 16us/sample - loss: 0.4338\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "X_train_a, X_train_b = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_valid_a, X_valid_b = X_valid_scaled[:, :5], X_valid_scaled[:, 2:]\n",
    "X_test_a, X_test_b = X_test_scaled[:, :5], X_test_scaled[:, 2:]\n",
    "X_new_a, X_new_b = X_test_a[:3], X_test_b[:3]\n",
    "\n",
    "history = model.fit((X_train_a, X_train_b), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_a, X_valid_b), y_valid))\n",
    "mse_test = model.evaluate((X_test_a, X_test_b), y_test)\n",
    "y_pred = model.predict((X_new_a, X_new_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many use cases in which you may want to have multiple outputs:\n",
    "\n",
    "- The task may demand it, for example you may want to locate and classify the main object in a picture. This is both a regression task (finding the coordinates of the object's center, as well as its width and height) and a classification task.\n",
    "\n",
    "- Similarly, you may have multiple independent tasks to perform based on the same data. Sure, you could train one neural network per task, but in mnay cases you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can learn features in the data that are useful across tasks.\n",
    "\n",
    "- Another use case is a regularization technique (i.e. a training constraint whose objective is to reduce overfitting and thus improve the model's ability to generalize). For example, you may want to add some auxiliary outputs in a neural network architecture (see figure below) to ensure that the underlying part of the network learns something useful on his own, without relying on the rest of the network.\n",
    "\n",
    "![](auxin.png)\n",
    "\n",
    "Adding extra outputs is quite easy: just connect them to the appropriate layers and add them to your model's list of outputs. For example, the following code builds the network represented in the figure above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5])\n",
    "input_b = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_a, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "aux_output = keras.layers.Dense(1)(hidden2)\n",
    "model = keras.models.Model(inputs = [input_a, input_b],\n",
    "                          outputs= [output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output will nedd its own loss function, so when we compile the model we should pass a list of losses (if we pass a a single loss, Keras will assume that the same loss must be used for all outputs). By default, Keras will compute all these losses and simply add them up to get the final loss used for training. However, we care much more about the main output than about the auxiliary output (as it is just used for regularization), so we want to give the main output's loss a much greater weight. Fortunately, it is possible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we train the model, we need to provide some labels for each output. In this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. So instead of passing `y_train`, we just nedd to pass `(y_train, y_train)`(and the same goes for `y_valid` and `y_test`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 1.0070 - dense_32_loss: 0.8954 - dense_33_loss: 2.0099 - val_loss: 0.5985 - val_dense_32_loss: 0.5198 - val_dense_33_loss: 1.3050\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5799 - dense_32_loss: 0.5162 - dense_33_loss: 1.1525 - val_loss: 0.5582 - val_dense_32_loss: 0.5017 - val_dense_33_loss: 1.0675\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5221 - dense_32_loss: 0.4707 - dense_33_loss: 0.9845 - val_loss: 0.6251 - val_dense_32_loss: 0.5889 - val_dense_33_loss: 0.9492\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4850 - dense_32_loss: 0.4432 - dense_33_loss: 0.8608 - val_loss: 0.6843 - val_dense_32_loss: 0.6590 - val_dense_33_loss: 0.9118\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4679 - dense_32_loss: 0.4330 - dense_33_loss: 0.7800 - val_loss: 0.8090 - val_dense_32_loss: 0.7931 - val_dense_33_loss: 0.9502\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4490 - dense_32_loss: 0.4195 - dense_33_loss: 0.7156 - val_loss: 0.8889 - val_dense_32_loss: 0.8754 - val_dense_33_loss: 1.0092\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4416 - dense_32_loss: 0.4166 - dense_33_loss: 0.6666 - val_loss: 1.1043 - val_dense_32_loss: 1.0998 - val_dense_33_loss: 1.1444\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4450 - dense_32_loss: 0.4230 - dense_33_loss: 0.6420 - val_loss: 1.1470 - val_dense_32_loss: 1.1370 - val_dense_33_loss: 1.2353\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4315 - dense_32_loss: 0.4122 - dense_33_loss: 0.6053 - val_loss: 1.4366 - val_dense_32_loss: 1.4378 - val_dense_33_loss: 1.4327\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4113 - dense_32_loss: 0.3922 - dense_33_loss: 0.5824 - val_loss: 1.4908 - val_dense_32_loss: 1.4858 - val_dense_33_loss: 1.5361\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4078 - dense_32_loss: 0.3896 - dense_33_loss: 0.5710 - val_loss: 1.8546 - val_dense_32_loss: 1.8560 - val_dense_33_loss: 1.8518\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3966 - dense_32_loss: 0.3800 - dense_33_loss: 0.5450 - val_loss: 1.9094 - val_dense_32_loss: 1.9065 - val_dense_33_loss: 1.9413\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3920 - dense_32_loss: 0.3764 - dense_33_loss: 0.5312 - val_loss: 2.1222 - val_dense_32_loss: 2.1160 - val_dense_33_loss: 2.1764\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4047 - dense_32_loss: 0.3917 - dense_33_loss: 0.5208 - val_loss: 2.2432 - val_dense_32_loss: 2.2429 - val_dense_33_loss: 2.2443\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3870 - dense_32_loss: 0.3735 - dense_33_loss: 0.5086 - val_loss: 2.3519 - val_dense_32_loss: 2.3436 - val_dense_33_loss: 2.4252\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4673 - dense_32_loss: 0.4556 - dense_33_loss: 0.5726 - val_loss: 2.3162 - val_dense_32_loss: 2.2887 - val_dense_33_loss: 2.5632\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4194 - dense_32_loss: 0.4074 - dense_33_loss: 0.5283 - val_loss: 2.5320 - val_dense_32_loss: 2.5068 - val_dense_33_loss: 2.7601\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3856 - dense_32_loss: 0.3721 - dense_33_loss: 0.5071 - val_loss: 2.8610 - val_dense_32_loss: 2.8491 - val_dense_33_loss: 2.9634\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3820 - dense_32_loss: 0.3679 - dense_33_loss: 0.5089 - val_loss: 3.1941 - val_dense_32_loss: 3.1884 - val_dense_33_loss: 3.2473\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3727 - dense_32_loss: 0.3597 - dense_33_loss: 0.4889 - val_loss: 3.0442 - val_dense_32_loss: 3.0280 - val_dense_33_loss: 3.1930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_a, X_train_b], [y_train, y_train], epochs = 20,\n",
    "    validation_data=([X_valid_a, X_valid_b], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we evaluate the model, Keras will return the total loss, as well as all the individual losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.4471 - dense_24_loss: 0.4301 - dense_25_loss: 0.5987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4470983144848846, 0.43009374, 0.5987113)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_a, X_test_b],[y_test, y_test])\n",
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the `predict()` method will return predictions for each output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.4236002],\n",
       "        [1.5668677],\n",
       "        [1.601843 ]], dtype=float32), array([[2.7642164],\n",
       "        [2.0975296],\n",
       "        [2.427959 ]], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_a, X_new_b])\n",
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you can build any sort of architecture you want quite easily with the Functional API. Let's ook at one last way you can build Keras models.\n",
    "\n",
    "## Building Duynamic MOdels Using the Subclassing API\n",
    "\n",
    "Both the Sequential API and the Functional API are declarative: you start by declaring which layers you want to use and how they should be connected, and only then you can start feeding the model some data for training or inference. This has many advantages: the model can easily be saved, cloned, shared, its structure can be displayed and analyzed, the framework can infer shapes and check types, so errors can be caught early (i.e. before any data ever goes through the model). It's also fairly easy to debug, since the whole model is just a static graph of layers. But the flip side is just that: it's static. Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For such cases, or simply if you prefer a more imperative programming style, the Subclassing API is for you.\n",
    "\n",
    "Simply subclass the `Model` class, create the layers you need in the constructor, and use them to perform the computations you want in the `call()` method. For example, creating an instance of the following `WideAndDeepModel` class gives us an equivalent model to the one we just built with the Functional API. You can then compile it, evaluate it and use it to make predictions, exactly like we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) #handles standard args (e.g. name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation = activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_a, input_b = inputs\n",
    "        hidden1 = self.hidden1(input_b)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate(input_a, hidden2)\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example ooks very much like the Functional API, except we do not need to create the inputs, we just use the `input` arugment to the `call()` method, and we separate the creation of the layers in the constructor from their usage in the `call()` method. However, the big difference is that you can do pretty much anything you want in the `call()` method: `for` loops, `if` statements, low-level TensorFlow operations... This makes it a great API for researchers experimenting with new ideas.\n",
    "\n",
    "However, this extra flexibility comes at a cost: your model's architecture is hidden within the `call()` method, so Keras cannot easily inspect it, it cannot save or clone it, and when you call the `summary()` method, you only get a list of layers, without any information on how they are connected to each other. Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Keras models can be used just like regular layers, so you can easily compose them to build complex architectures.\n",
    "\n",
    "## Saving and Restoring a Model\n",
    "\n",
    "Saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 1.3774\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5032\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5456\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4795\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.9068\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 1.1869\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4231\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4673\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4400\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3614\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3570\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6372\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3759\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6169\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5270\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3489\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3440\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4039\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3434\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6277\n"
     ]
    }
   ],
   "source": [
    "model = createmodel()\n",
    "model.fit(X_train_scaled, y_train, epochs=20)\n",
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will save both the model's architecture (including every layer's hyperparameters) and the value of all the model parameters for every layer (e.g. connection weights and biases), using the `HDF5`  format. It also saves the optimizer (including its hyperparameters and any state it may have).\n",
    "\n",
    "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution**:\n",
    "\n",
    "This will work when using the Sequential API or the Functional API, but unfortunately not when using Model subclassing. However, you can use `save_weights()` and `load_weights()` to at least save and restore the model parameters (but you will need to save and restore everything else yourself).\n",
    "\n",
    "But what if training lasts several hours? This is quite common, especially when training on large datasets. In this case, you should not only save your model at the end of training, but also save checkpoints at regular intervals during training. But how can you tell the `fit()` method to save checkpoints? The answer is: using callbacks.\n",
    "\n",
    "## Using Callbacks\n",
    "\n",
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call during training at the start and end of training, at the start and end of each epoch and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of you model at regular intervals during training, by default at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 106us/sample - loss: 0.7556\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5698\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.8450\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 2.4339\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 1.2855\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4282\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4149\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3825\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4122\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4211\n"
     ]
    }
   ],
   "source": [
    "model = createmodel() # build and compile model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint`. In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. This is a simple way to implement early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3590 - val_loss: 2.2199\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3575 - val_loss: 2.0196\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3401 - val_loss: 2.1451\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3374 - val_loss: 2.6385\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3396 - val_loss: 2.9923\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3354 - val_loss: 3.0760\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3436 - val_loss: 3.0575\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3263 - val_loss: 3.1209\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3231 - val_loss: 3.2798\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3560 - val_loss: 3.7465\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", \n",
    "                                                save_best_only=True)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model. You can combine both callbacks to both save checkpoints of your model (in case your computer crashes), and actually interrupt training early when there is no progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.3430 - val_loss: 2.3206\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3416 - val_loss: 2.4887\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3350 - val_loss: 3.0678\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3365 - val_loss: 2.9253\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3287 - val_loss: 2.7615\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3336 - val_loss: 3.2060\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3206 - val_loss: 3.5643\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3216 - val_loss: 3.3557\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3172 - val_loss: 3.8172\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3174 - val_loss: 3.8697\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3126 - val_loss: 4.0828\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of epochs can be set to a large value since training will stop automatically when there is no more progress. Moreover, there is no need t orestore the best model saved in this case since the `EarlyStopping` callback will keep track of the best weights and restore them for us at the end of training.\n",
    "\n",
    "If you need extra control, you can easily write your own custom callbacks. For example, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, you can implement `on_train_begin()`, `on_train_end()`, `on_epoch_begin()`, `on_batch_begin()`, and `on_batch_end()`.\n",
    "\n",
    "Moreover, callbacks can also be used during evaluation and predictions, should you ever need them (e.g. for debugging). In this case, you should implement `on_test_begin()`, `on_test_end()`, `on_test_batch_begin()`, `on_test_batch_end()`, or `on_test_batch_end()` (called by `evaluate()`), or `on_predict_begin()`, `on_predict_end()`, `on_predict_batch_begin()`, or `on_predict_batch_end()` (called by `predict()`).\n",
    "\n",
    "Now let's take a look at one more tool you should definitely have in your toolbox when using tf.keras: TensorBoard.\n",
    "\n",
    "## Visualization Using TensorBoard\n",
    "\n",
    "TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you and more! This tool is installed automatically when you install TensorFlow.\n",
    "\n",
    "To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called *event files*. Each binary data record is called a *summary*. The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations: this allows you to visualize live data (with a short delay), such as the learning curves during training. In general, you want to point the TensorBoard server to a root log directory, and configure your program so that it writes to a different subdirectory everytime it runs. This way, the same TensorBoard server instance will allow you to visualize and compare data from multiple runs of your program, without getting everything mixed up.\n",
    "\n",
    "So let's start by defining the root log directory we will use for our TensorBoard logs, plus a small function that will generate a subdirectory path based on the current date and time, so that it is different at every run. You may want to include extra information in the log directory name, such as hyperparameter values that you are testing, to make it easier to know what you are looking at in TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\mu_logs\\\\run_2019_08_23-14_51_17'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the good news is that Keras provides a nice TensorBoard callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 105us/sample - loss: 3.0001 - val_loss: 4.4934\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 3.2169 - val_loss: 2.9143\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 80.1479 - val_loss: 0.5635\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5396 - val_loss: 0.5118\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5288 - val_loss: 0.6263\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5888 - val_loss: 1.7390\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.6797 - val_loss: 0.4899\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5272 - val_loss: 0.5448\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5916 - val_loss: 0.9664\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.6470 - val_loss: 0.9346\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5559 - val_loss: 0.4667\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5136 - val_loss: 0.5328\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.5217 - val_loss: 0.7359\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5414 - val_loss: 0.9011\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5463 - val_loss: 0.7891\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "model = createmodel()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=30,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this code, the TensorBoard callback will take care of creating the log directory for you (along with its parent directories if needed), and during training it will create event files and write summaries to them. After runing the program a second time (perhaps changing some hyperparameter value), you will end up with a directory structure similar to this one:\n",
    "\n",
    "![](dir.png)\n",
    "\n",
    "Next you need to start the TensorBoard server. Run the following command at the root of the project (or from anywhere else as long as you point to the appropriate log directory).\n",
    "\n",
    "![](cmnd.png)\n",
    "\n",
    "Finally, open up a web browser to http://localhost:6006. You should see TensorBoards web interface. Click on the SCALARS tab to view the learning curves. \n",
    "\n",
    "## Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "The flexibility of NN is also one of their main drawbacks: there are many hyperparameters to tweak. Not only can you use any imaginable network architecture, but even in a simple MLP you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic, and much more. How do you know what combination of hyperparameters is the best for your task?\n",
    "\n",
    "One option is to simply try many combinations of hyperparameters and see which one works best on the validation set (or using K-fold cross-validation). For this, one approach is simply use `GridSearchCV` or `RandomizedSearchCV` to explore the hyperparameter space. \n",
    "\n",
    "To do so, we need to wrap out Keras models in objects that mimic regular Scikit-Learn regressors. The first step is to create a function that will build and compile a Keras model, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a simple Sequential model for univariate regression (only one output neuron), with the given input shape and the given number of hidden layers and neurons, and it compiles it using an `SGD` optimizer configured with the given learning rate. The `options` dict is used to ensure that the first layer is properly given the input shape (note that if `n_hidden=0`, the first layer will be the output layer). It is good practice to provide reasonable defaults to as many hyperparameters as you can, as Scikit-Learn does.\n",
    "\n",
    "Next, let's create a `KerasRegressor` based on this `build_model()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `KerasRegressor` object is a thin wrapper around the Keras model built using `build_model()`. Since we did not specify any hyperparameter when creating it, it will just use the default hyperparameters we defined in `build_model()`. Now we can use this object like a regular Scikit-Learn regressor: we can train it using its `fit()` method, then evaluate it using its `score()` method, and use it to make predictions using its `predict()` method. Note that any extra parameters you pass to the `fit()` method will simply get passed to the underlying Keras model. Also note that the score will be the opposite of the MSE because Scikit-Learn wants scores, not losses (i.e. higher should be better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 1.3645 - val_loss: 0.8785\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.7902 - val_loss: 0.6147\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6389 - val_loss: 0.5305\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5576 - val_loss: 0.4957\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5196 - val_loss: 0.4789\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4942 - val_loss: 0.4807\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4763 - val_loss: 0.4881\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4624 - val_loss: 0.5101\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4537 - val_loss: 0.5274\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4448 - val_loss: 0.5509\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4374 - val_loss: 0.5842\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4325 - val_loss: 0.6097\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4266 - val_loss: 0.6480\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4210 - val_loss: 0.6715\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4167 - val_loss: 0.7028\n",
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.4541\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train_scaled, y_train, epochs=100,\n",
    "             validation_data=(X_valid_scaled, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test_scaled, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not actually want to train and evaluate a single model like this, we want to train hundreds of variants and see which one performs best on the validation set. Since there are many hyperparameters, it is preferable to use a randomized search rather than grid search (as we discussed in chapter 2). Let's try to explore the number of hidden layers, the number of neurons and the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 198us/sample - loss: 1.5573 - val_loss: 0.7679\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7813 - val_loss: 0.7144\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7943 - val_loss: 0.6007\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6986 - val_loss: 0.5397\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5731 - val_loss: 0.4889\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5316 - val_loss: 0.4656\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5043 - val_loss: 0.4571\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4875 - val_loss: 0.4519\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4748 - val_loss: 0.4520\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4649 - val_loss: 0.4590\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4576 - val_loss: 0.4646\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4501 - val_loss: 0.4795\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4449 - val_loss: 0.4867\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4391 - val_loss: 0.5090\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4340 - val_loss: 0.5234\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4302 - val_loss: 0.5295\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4257 - val_loss: 0.5505\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4216 - val_loss: 0.5683\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.4126\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.4194\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 216us/sample - loss: 1.4453 - val_loss: 0.7028\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6649 - val_loss: 0.5908\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6021 - val_loss: 0.5392\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5664 - val_loss: 0.5069\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5364 - val_loss: 0.4812\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5187 - val_loss: 0.4716\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5073 - val_loss: 0.4629\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4978 - val_loss: 0.4663\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4904 - val_loss: 0.4765\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4779 - val_loss: 0.4687\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4706 - val_loss: 0.4855\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4704 - val_loss: 0.4781\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4647 - val_loss: 0.4937\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4576 - val_loss: 0.5011\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4532 - val_loss: 0.5172\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4530 - val_loss: 0.5339\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4454 - val_loss: 0.5394\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.4239\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4431\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 208us/sample - loss: 1.6089 - val_loss: 0.6732\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6617 - val_loss: 0.5842\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6118 - val_loss: 0.5341\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5546 - val_loss: 0.4901\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5195 - val_loss: 0.4631\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4919 - val_loss: 0.4548\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4763 - val_loss: 0.4464\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4624 - val_loss: 0.4577\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4562 - val_loss: 0.4500\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4469 - val_loss: 0.4681\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4401 - val_loss: 0.4643\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4325 - val_loss: 0.4773\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4283 - val_loss: 0.4844\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4231 - val_loss: 0.5093\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4192 - val_loss: 0.5122\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4161 - val_loss: 0.5381\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4124 - val_loss: 0.5408\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4446\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4096\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 219us/sample - loss: 1.5553 - val_loss: 0.7804\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.7766 - val_loss: 0.7152\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7017 - val_loss: 0.6615\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6632 - val_loss: 0.6278\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6332 - val_loss: 0.5933\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6054 - val_loss: 0.5704\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5818 - val_loss: 0.5472\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.5611 - val_loss: 0.5277\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.5431 - val_loss: 0.5112\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.5270 - val_loss: 0.4998\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.5129 - val_loss: 0.4937\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5001 - val_loss: 0.4885\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4888 - val_loss: 0.4782\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4787 - val_loss: 0.4787\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4698 - val_loss: 0.4758\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4619 - val_loss: 0.4789\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4550 - val_loss: 0.4815\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4493 - val_loss: 0.4856\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4437 - val_loss: 0.4907\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4386 - val_loss: 0.4960\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4343 - val_loss: 0.4981\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4302 - val_loss: 0.5109\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4265 - val_loss: 0.5166\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4229 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4198 - val_loss: 0.5362\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.4228\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4175\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 240us/sample - loss: 2.9237 - val_loss: 1.0859\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8854 - val_loss: 0.7554\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7365 - val_loss: 0.6882\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6881 - val_loss: 0.6492\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6581 - val_loss: 0.6202\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6336 - val_loss: 0.5942\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6119 - val_loss: 0.5735\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5931 - val_loss: 0.5507\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5758 - val_loss: 0.5313\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5599 - val_loss: 0.5155\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5460 - val_loss: 0.5006\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5336 - val_loss: 0.4884\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5225 - val_loss: 0.4784\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5122 - val_loss: 0.4709\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5026 - val_loss: 0.4647\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4943 - val_loss: 0.4611\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4865 - val_loss: 0.4593\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4784 - val_loss: 0.4608\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4732 - val_loss: 0.4601\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4674 - val_loss: 0.4620\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4618 - val_loss: 0.4650\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4556 - val_loss: 0.4694\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4527 - val_loss: 0.4735\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4474 - val_loss: 0.4808\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4440 - val_loss: 0.4874\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4387 - val_loss: 0.4974\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4355 - val_loss: 0.5058\n",
      "3870/3870 [==============================] - 0s 28us/sample - loss: 0.4303\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4327\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 223us/sample - loss: 1.7934 - val_loss: 0.8349\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7703 - val_loss: 0.6812\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6707 - val_loss: 0.6352\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6308 - val_loss: 0.5981\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5979 - val_loss: 0.5678\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5716 - val_loss: 0.5445\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5478 - val_loss: 0.5238\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5264 - val_loss: 0.5085\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5092 - val_loss: 0.4957\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4937 - val_loss: 0.4954\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4796 - val_loss: 0.4965\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4682 - val_loss: 0.4940\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4577 - val_loss: 0.5008\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.4484 - val_loss: 0.5055\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4402 - val_loss: 0.5129\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.4331 - val_loss: 0.5335\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4270 - val_loss: 0.5498\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4213 - val_loss: 0.5666\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4160 - val_loss: 0.5734\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4118 - val_loss: 0.5880\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4076 - val_loss: 0.6299\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4042 - val_loss: 0.6276\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.4278\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4010\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 230us/sample - loss: 3.5860 - val_loss: 1.9509\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.4824 - val_loss: 1.1105\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 1.0111 - val_loss: 0.8583\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8353 - val_loss: 0.7463\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7559 - val_loss: 0.6881\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7131 - val_loss: 0.6531\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6854 - val_loss: 0.6283\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6651 - val_loss: 0.6092\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6489 - val_loss: 0.5935\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6350 - val_loss: 0.5800\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6227 - val_loss: 0.5680\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6116 - val_loss: 0.5573\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6014 - val_loss: 0.5478\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5919 - val_loss: 0.5390\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5833 - val_loss: 0.5311\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5749 - val_loss: 0.5238\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5674 - val_loss: 0.5174\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5601 - val_loss: 0.5113\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5533 - val_loss: 0.5057\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5468 - val_loss: 0.5011\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5409 - val_loss: 0.4967\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5351 - val_loss: 0.4927\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5300 - val_loss: 0.4893\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5249 - val_loss: 0.4862\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5202 - val_loss: 0.4839\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5158 - val_loss: 0.4818\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5117 - val_loss: 0.4798\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5077 - val_loss: 0.4778\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5040 - val_loss: 0.4765\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5005 - val_loss: 0.4756\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4972 - val_loss: 0.4744\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4941 - val_loss: 0.4741\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4911 - val_loss: 0.4739\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4884 - val_loss: 0.4735\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4857 - val_loss: 0.4741\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4832 - val_loss: 0.4751\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4808 - val_loss: 0.4741\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4786 - val_loss: 0.4756\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4764 - val_loss: 0.4764\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4744 - val_loss: 0.4773\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4723 - val_loss: 0.4788\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4706 - val_loss: 0.4801\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4688 - val_loss: 0.4817\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4670 - val_loss: 0.4834\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.4542\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4657\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 234us/sample - loss: 4.0987 - val_loss: 2.3854\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.6359 - val_loss: 1.3570\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.0813 - val_loss: 1.0385\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.9064 - val_loss: 0.9052\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8354 - val_loss: 0.8318\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7951 - val_loss: 0.7809\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7662 - val_loss: 0.7403\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7423 - val_loss: 0.7076\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7218 - val_loss: 0.6790\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7032 - val_loss: 0.6547\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.6867 - val_loss: 0.6331\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6715 - val_loss: 0.6139\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6576 - val_loss: 0.5971\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6448 - val_loss: 0.5818\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6330 - val_loss: 0.5674\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6218 - val_loss: 0.5549\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6117 - val_loss: 0.5432\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6023 - val_loss: 0.5328\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5934 - val_loss: 0.5232\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5851 - val_loss: 0.5146\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5774 - val_loss: 0.5068\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5699 - val_loss: 0.4993\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5630 - val_loss: 0.4928\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5562 - val_loss: 0.4871\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5499 - val_loss: 0.4815\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5438 - val_loss: 0.4766\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5381 - val_loss: 0.4725\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5326 - val_loss: 0.4683\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5275 - val_loss: 0.4649\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5225 - val_loss: 0.4619\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5179 - val_loss: 0.4596\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5136 - val_loss: 0.4573\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5095 - val_loss: 0.4549\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5055 - val_loss: 0.4535\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5019 - val_loss: 0.4519\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4985 - val_loss: 0.4505\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4954 - val_loss: 0.4496\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4925 - val_loss: 0.4492\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4898 - val_loss: 0.4487\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4872 - val_loss: 0.4485\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4848 - val_loss: 0.4476\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4826 - val_loss: 0.4475\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4805 - val_loss: 0.4476\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4784 - val_loss: 0.4482\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4766 - val_loss: 0.4487\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4748 - val_loss: 0.4488\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4731 - val_loss: 0.4490\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4715 - val_loss: 0.4499\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4700 - val_loss: 0.4503\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4686 - val_loss: 0.4512\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4672 - val_loss: 0.4522\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4658 - val_loss: 0.4535\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4556\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4647\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 218us/sample - loss: 3.5940 - val_loss: 2.1953\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.6782 - val_loss: 1.1931\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.0284 - val_loss: 0.8416\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7874 - val_loss: 0.7053\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6941 - val_loss: 0.6490\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6514 - val_loss: 0.6186\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6266 - val_loss: 0.5994\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6100 - val_loss: 0.5846\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5967 - val_loss: 0.5725\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5854 - val_loss: 0.5616\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5756 - val_loss: 0.5517\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5665 - val_loss: 0.5429\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5581 - val_loss: 0.5344\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5504 - val_loss: 0.5271\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5434 - val_loss: 0.5213\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5368 - val_loss: 0.5147\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5306 - val_loss: 0.5088\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5250 - val_loss: 0.5042\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5195 - val_loss: 0.5003\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5146 - val_loss: 0.4956\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5099 - val_loss: 0.4916\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5055 - val_loss: 0.4885\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5013 - val_loss: 0.4846\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4975 - val_loss: 0.4824\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4938 - val_loss: 0.4798\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4903 - val_loss: 0.4775\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4870 - val_loss: 0.4746\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4839 - val_loss: 0.4727\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4809 - val_loss: 0.4709\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4780 - val_loss: 0.4694\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4755 - val_loss: 0.4681\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4730 - val_loss: 0.4674\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4704 - val_loss: 0.4671\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4682 - val_loss: 0.4665\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4659 - val_loss: 0.4655\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4638 - val_loss: 0.4653\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4617 - val_loss: 0.4645\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4598 - val_loss: 0.4640\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4579 - val_loss: 0.4639\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4561 - val_loss: 0.4647\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4544 - val_loss: 0.4642\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4527 - val_loss: 0.4642\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4511 - val_loss: 0.4642\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4495 - val_loss: 0.4648\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4480 - val_loss: 0.4656\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4466 - val_loss: 0.4660\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4451 - val_loss: 0.4664\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4438 - val_loss: 0.4672\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4424 - val_loss: 0.4677\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.4763\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.4413\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 2s 171us/sample - loss: 1.9155 - val_loss: 0.8002\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.7334 - val_loss: 0.6414\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.6543 - val_loss: 0.5868\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.6123 - val_loss: 0.5461\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.5788 - val_loss: 0.5144\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5508 - val_loss: 0.4870\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5278 - val_loss: 0.4667\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5090 - val_loss: 0.4493\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4932 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4813 - val_loss: 0.4282\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4707 - val_loss: 0.4226\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.4615 - val_loss: 0.4200\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4543 - val_loss: 0.4177\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4474 - val_loss: 0.4233\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.4423 - val_loss: 0.4226\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4364 - val_loss: 0.4297\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4312 - val_loss: 0.4362\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4257 - val_loss: 0.4566\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4217 - val_loss: 0.4676\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4171 - val_loss: 0.4868\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4131 - val_loss: 0.4973\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4096 - val_loss: 0.5149\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4063 - val_loss: 0.5401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000018F01000780>,\n",
       "          fit_params=None, iid='warn', n_iter=3, n_jobs=None,\n",
       "          param_distributions={'n_hidden': [1, 2], 'n_neurons': [30, 40], 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018F0B2CA908>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1, 2], # [0, 1, 2, 3]\n",
    "    \"n_neurons\": [30,40],# np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=3, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train, epochs=100,\n",
    "                 validation_data=(X_valid_scaled, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is identical to what we did in chapter 2, with the exception that we pass extra parameters to the `fit()` method: they simply get relayed to the underlying Keraas models Note that `RandomizedSearchCV` uses K-fold cross-validation, so it does not use `X_valid` and `y_valid`. These are just used for ealy stopping.\n",
    "\n",
    "The exploration may last many hours depending on the hardware, the size of the dataset, the complexity of the model and the value of `n_iter` and `cv`. When it is over, you can access the best parameters found, the best score, and the trained Keras model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0013685527598336527, 'n_hidden': 2, 'n_neurons': 30}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42694373879321784"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now save this model, evaluate it on the test set, and if you are satisfied with its performance, deploy it to production. Using randomized search is not too hard, and it works well for many fairly simple problems. However, when training is slow (e.g. for more complex problems with larger datasets), this approach will only explore a tiny portion of the hyperparameter space. You can partially alleviate this problem by assisting the search process manually: first run a quick random search using wide ragnes of hyperparameter values, then run another search using smaller ranges of values centered on the best ones found during the first run and so on. This will hopefully zoom in to a good set of hyperparameters. However, this is very time consuming, and probably not the best use of your time.\n",
    "\n",
    "Fortunately, there are many techniques to explore a search space much more efficiently than randomly. Their core idea is simple: when a region of the space turns out to be good, it should be explored more. This takes care of the \"zooming\" process for you and leads to much better solutions in much less time. Here are a few Python libraries you can use to optimize hyperparameters:\n",
    "\n",
    "- Hyperopt: a popular Python library for optimizing over all sorts of complex search spaces (including real values such as the learning rate, or discrete values such as the number of layers).\n",
    "\n",
    "- Hyperas,kopt or Talos: optimizing hyperparameters for Keras model (the first two are based on Hyperopt)\n",
    "\n",
    "- Scikit-Optimize (skopt): a general-purpose optimization library. The `BayesSearchCV` class performs Bayesian optimizatiojn using an interface similar to `GridSearchCV`\n",
    "\n",
    "- Spearmint: a Bayesian optimization library.\n",
    "\n",
    "- Sklearn-Deap: a hyperparameter optimization library based on evolutionary algorithms, also with a `GridSearchCV`-like interface\n",
    "\n",
    "Moreover, many companies offer services for hyperparameter optimization. \n",
    "\n",
    "Hyperparameter tuning is still an active area of research. Evolutionary algorithms are making a comeback lately. For example, check out DeepMinds excellent 2017 paper, where they jointly optimize a population of models and their hyperparameters. Google also used an evolutionary approach, not just to search for hyperparameters, but also to look for the best neural network architecture for the problem. They call this AutoML, and it is already available as a cloud service. Perhaps the days of building neural networks manually will soon be over? Check out Googles post on this topic. In fact, evolutionary algorithms have also been used successfully to train individual neural networks, replacing the ubiquitous Gradient Descent!\n",
    "\n",
    "Despite all this, it still helps to have an idea of what values are reasonable for each hyperparameter, so you can build a quick prototype, and restrict the search space. Here are a few guidelines for choosing the number of hidden layers and neurons in an MLP, and selecting good values for some of the main hyperparameters.\n",
    "\n",
    "## Number of Hidden Layers\n",
    "\n",
    "For many problems, you can just begin with a single hidden layer and you will get reasonable results. It has actually been shown that an MLP with just one hidden layer can model even the most complex functions provided it has enough neurons. For a long time, these facts convinced researchers that there was no need to investigate any deeper neural networks. But they overlooked the fact that deep networks have a much higher *parameter efficiency* than shallow ones: they can model complex functions using exponentially fewer neurons than shallow nets, allowing them to reach much better performance with the same amount of training data.\n",
    "\n",
    "To understand why, suppose you are asked to draw a forest using some drawing software, but you are forbidden to use copy/paste. You would have to draw each tree individually, branch per branch, leaf per leaf. If you could instead draw one leaf, copy/paste it to draw a branch, then copy/paste that branch to create a tree, and finally copy/paste this tree to make a forest, you would be finished in no time. Real world data is often structured in such a hierarchical way and Deep Neural Networks automatically take advantage of this fact: lower hidden layers model low-level structures (e.g., line segments of various shapes and orientations), intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g., squares, circles), and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g., faces).\n",
    "\n",
    "Not only does this hierarchical architecture help DNNs converge faster to a good solution, it also improves their ability to generalize to new datasets. For example, if you have already trained a model to recognize faces in pictures, and you now want to train a new neural network to recognize hairstyles, then you can kickstart training by reusing the lower layers of the first network. Instead of randomly initializing the weights and biases of the first few layers of the new neural network, you can initialize them to the value of the weights and biases of the lower layers of the first network. This way the network will not have to learn from scratch all the low-level structures that occur in most pictures; it will only have to learn the higher-level structures (e.g., hairstyles). This is called *transfer learning*.\n",
    "\n",
    "In summary, for many problems you can start with just one or two hidden layers and it will work just fine (e.g., you can easily reach above 97% accuracy on the MNIST dataset using just one hidden layer with a few hundred neurons, and above 98% accuracy using two hidden layers with the same total amount of neurons, in roughly the same amount of training time). For more complex problems, you can gradually ramp up the number of hidden layers, until you start overfitting the training set. Very complex tasks, such as large image classification or speech recognition, typically require networks with dozens of layers (or even hundreds, but not fully connected ones, as we will see in Chapter 14), and they need a huge amount of training data. However, you will rarely have to train such networks from scratch: it is much more common to reuse parts of a pretrained state-of-the-art network that performs a similar task. Training will be a lot faster and require much less data.\n",
    "\n",
    "## Number of Neurons per Hidden Layer\n",
    "\n",
    "Obviously the number of neurons in the input and output layers is determined by the type of input and output your task requires. For example, the MNIST task requires 28 x 28 = 784 input neurons and 10 output neurons.\n",
    "\n",
    "As for the hidden layers, it used to be a common practice to size them to form a pyramid, with fewer and fewer neurons at each layerthe rationale being that many low level features can coalesce into far fewer high-level features. For example, a typical neural network for MNIST may have three hidden layers, the first with 300 neurons, the second with 200, and the third with 100. However, this practice has been largely abandoned now, as it seems that simply using the same number of neurons in all hidden layers performs just as well in most cases, or even better, and there is just one hyperparameter to tune instead of one per layerfor example, all hidden layers could simply have 150 neurons. However, depending on the dataset, it can sometimes help to make the first hidden layer bigger than the others.\n",
    "\n",
    "Just like for the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting. In general you will get more bang for the buck by increasing the number of layers than the number of neurons per layer. Unfortunately, as you can see, finding the perfect amount of neurons is still somewhat of a dark art.\n",
    "\n",
    "A simpler approach is to pick a model with more layers and neurons than you actually need, then use early stopping to prevent it from overfitting (and other regularization techniques, such as dropout, as we will see in Chapter 11). This has been dubbed the stretch pants approach: instead of wasting time looking for pants that perfectly match your size, just use large stretch pants that will shrink down to the right size.\n",
    "\n",
    "## Learning Rate, Batch Size and Other Hyperparameters\n",
    "\n",
    "The number of hidden layers and neurons are not the only hyperparameters you can tweak in an MLP. Here are some of the most important ones, and some tips on how to set them:\n",
    "\n",
    "- The learnign rate is arguably the most important hyperparameter. In general, the optimal learning rate is about half of the maximum learning rate (i.e. the learning rate above which the training algorithm diverges, as seen in chapter 4). So a simple approach for tuning the learning rate is to start with a large value that makes the training algorithm diverge, then divide this value by 3 and try again, and repeat until the training algorithm stops diverging. At that point, you generally won't be too far from the optimal learning rate. That said, it is sometimes useful to reduce the learning rate during training: we will discuss this in Chapter 11.\n",
    "\n",
    "- Choosing a better optimizer than plain old Mini-batch Gradient Descent (and tuning its hyperparameters) is also quite important (chapter 11).\n",
    "\n",
    "- The batch size can also have a significant impact on your model's performance and the training time. IN general the optimal batch size will be lower than 32. A small batch size ensures that each training iteration is very fast, and although a large batch size will give a more precise estimate of the gradients, in practice this does not matter much since the optimization landscape is quite complex, and the direction of the true gradients do not point precisely in the direction of the optimum. However, having a batch size greater than 10 helps take advantage of hardware and software optimizations, in particular for matrix multiplications, so it will speed up training. Moreover, if you use *Batch Normalization* (see chapter 11), the batch size should not be too small (in general no less than 20).\n",
    "\n",
    "- We discussed the choice of the activation function earlier in this chapter: in general the ReLU activation function will be a good default for all hidden layers. For the output layer, it really depends on your task.\n",
    "\n",
    "- In most caases, the number of training iterations does not actually need to be tweaked: just use early stopping instead.\n",
    "\n",
    "For more best practices, make sure to read Yoshua Bengio's great [2012 paper]( https://arxiv.org/abs/1206.5533), which presents many practical recommendations for deep networks.\n",
    "\n",
    "This concludes this introduction to arti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
